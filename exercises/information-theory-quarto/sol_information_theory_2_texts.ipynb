{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6afa50",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "label: colab_R_link\n",
    "https://colab.research.google.com/github/slds-lmu/lecture_sl/blob/main/exercises/information-theory-quarto/inserted/sol_information_theory_2_R.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d09da",
   "metadata": {},
   "source": [
    "label: colab_python_link\n",
    "https://colab.research.google.com/github/slds-lmu/lecture_sl/blob/main/exercises/information-theory-quarto/inserted/sol_information_theory_2_py.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99de1c3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "label: exercise_3\n",
    "# Exercise 3: Smoothed Cross-Entropy Loss (b)\n",
    "Implement the smoothed cross-entropy. We provide the signature of the function here as a reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419de6b",
   "metadata": {},
   "source": [
    "label: solution\n",
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52623088",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "label: solution_motivation\n",
    "## Motivation\n",
    "Before starting the solutions, let's try to develop a feeling for the smoothed cross-entropy loss by plotting it for different values of the smoothing parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b48e55c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "label: motivation_plotting\n",
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83176c1f",
   "metadata": {},
   "source": [
    "label: motivation_interpretation\n",
    "### Interpretation\n",
    "We can see that for the standard CE (black line) the loss goes to zero  when the predicted probability for the true class goes to one (over-confident prediction). On the other hand, the smoothed CE (colored lines) takes on comparable values whenever the predicted probabilities are small (e.g before 0.2), but once the predicted probability approaches one, the curves actually go up, and by that penalizing over-confident predictions. The larger the smoothing parameter, the more pronounced this effect is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511ed22",
   "metadata": {},
   "source": [
    "label: solution_main\n",
    "## Main solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b7cc2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "label: confident_model\n",
    "### Confident Model\n",
    "Let's build a \"confident model\". The model will have very high predicted probabilities for one of the labels. Additionally, we will add one sample with a not confident prediction (i.e. the predicted probabilities are close to uniform) and see how the smoothed cross-entropy behaves in this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05985de5",
   "metadata": {},
   "source": [
    "label: solution_interpretation\n",
    "### Interpretation\n",
    "We can see that by adding smoothing we have changed the labels matrix (1's have decrease to 0.86 and zeros ent up to 0.06) which resulted in average loss increased from around 0.29 to 0.61 (~2.13x increase).\n",
    "\n",
    "Let's observe the changes in the loss for each sample:\n",
    "| Sample ID | Prediction distribution  | Prediction true label | Standard CE | Smoothed CE | Change factor |\n",
    "| :-------: | -------------------------------------- | :------: | ---------: | ----------: | ------------: |\n",
    "|     1     | (0.850, 0.100, 0.050)                  |   0.85  |      0.163 |       0.494 |         3.040 |\n",
    "|     2     | (0.050, 0.900, 0.050)                  |   0.90  |      0.105 |       0.491 |         4.658 |\n",
    "|     3     | (0.020, 0.950, 0.030)                  |   0.95  |      0.051 |       0.539 |        10.509 |\n",
    "|     4     | (0.130, 0.020, 0.850)                  |   0.85  |      0.163 |       0.538 |         3.308 |\n",
    "|     5     | (0.860, 0.040, 0.100)                  |   0.86  |      0.151 |       0.499 |         3.307 |\n",
    "|     6     | (0.340, 0.330, 0.330)                  |   0.34  |      1.079 |       1.083 |         1.004 |\n",
    "\n",
    "We can observe that the loss for the not confident prediction (sample 6) has remained practically unchanged, but for the confident predictions (samples 1-5) the loss has increased significantly. The increase is especially noticeable for the 3rd sample, for which the prediction was very confident (0.95) and the loss has increased by a factor of 10.5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
