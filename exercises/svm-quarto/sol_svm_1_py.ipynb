{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0e6afa50",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Python - SVM - Exercise 1\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d09da",
   "metadata": {},
   "source": [
    "<a href=\"INSERT_colab_python_link\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f33a1",
   "metadata": {},
   "source": [
    "label: exercise\n",
    "# Exercise\n",
    "Write your own stochastic subgradient descent routine to solve the soft-margin SVM in the primal formulation.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Use the regularized-empirical-risk-minimization formulation, i.e., an optimization criterion without constraints.\n",
    "- No kernels, just a linear SVM.\n",
    "- Compare your implementation with an existing implementation (e.g., `kernlab` in R or `sklearn.svm.SVC` in Pythong). Are your results similar? Note that you might have to switch off the automatic data scaling in the already existing implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2402de0",
   "metadata": {},
   "source": [
    "label: import_and_globals\n",
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: import_and_globals\n",
    "\n",
    "# You may need to first run:\n",
    "# pip install numpy pandas matplotlib scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SVM regularization parameter (inverse of lambda)\n",
    "C = 1\n",
    "\n",
    "np.random.seed(509) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f24bd",
   "metadata": {},
   "source": [
    "label: algorithm_explanation\n",
    "\n",
    "# PEGASOS Algorithm Explanation\n",
    "\n",
    "The PEGASOS algorithm is a stochastic gradient descent method for training linear SVMs. It works by:\n",
    "\n",
    "1. **Random Sampling**: At each iteration, randomly select one training example\n",
    "2. **Weight Decay**: Apply regularization by shrinking the weight vector: `θ ← (1 - λα)θ`\n",
    "3. **Margin Check**: If the selected example is within the margin (i.e., `y_i * f(x_i) < 1`), update the weights: `θ ← θ + α * y_i * x_i`\n",
    "4. **Repeat**: Continue until convergence or maximum iterations\n",
    "\n",
    "More details can be found in the [i2ml chapter on linear SVMs](https://slds-lmu.github.io/i2ml/chapters/16_linear_svm/16-05-optimization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd7cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: pegasos_implementation\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def pegasos_linear(y, X, nr_iter=50_000, theta=None, lambda_param=1, alpha=0.01):\n",
    "    \"\"\"\n",
    "    PEGASOS Algorithm for Linear SVM\n",
    "    \n",
    "    This function implements the PEGASOS (Primal Estimated sub-GrAdient SOlver for SVM) \n",
    "    algorithm, which is a stochastic gradient descent method for training linear SVMs.\n",
    "    \n",
    "    For more details, see https://slds-lmu.github.io/i2ml/chapters/16_linear_svm/16-05-optimization\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : array-like\n",
    "        outcome vector (should be -1 or +1)\n",
    "    X : array-like\n",
    "        design matrix (including a column of 1s for the intercept)\n",
    "    nr_iter : int, default=50000\n",
    "        number of iterations for the algorithm\n",
    "    theta : array-like, default=None\n",
    "        starting values for thetas (if None, random initialization)\n",
    "    lambda_param : float, default=1\n",
    "        penalty parameter (regularization strength)\n",
    "    alpha : float, default=0.01\n",
    "        step size for weight decay\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    theta : array\n",
    "        vector containing the learned parameters\n",
    "    \"\"\"\n",
    "    if theta is None:\n",
    "        theta = np.random.randn(X.shape[1])\n",
    "    else:\n",
    "        theta = np.array(theta)\n",
    "    \n",
    "    n = len(y)\n",
    "    \n",
    "    for _ in range(nr_iter):\n",
    "        f_current = X @ theta\n",
    "        i = random.randint(0, n - 1)  # randomly sample one training example\n",
    "        \n",
    "        # Weight decay step\n",
    "        theta = (1 - lambda_param * alpha) * theta\n",
    "        \n",
    "        # Add gradient step if the example is within the margin\n",
    "        if y[i] * f_current[i] < 1:\n",
    "            theta = theta + alpha * y[i] * X[i, :]\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba374fc",
   "metadata": {},
   "source": [
    "label: data_setup\n",
    "\n",
    "## Data Generation and Setup\n",
    "\n",
    "For R we'll use the `mlbench.twonorm` dataset, which generates a two-class problem with two features. This is a classic benchmark dataset for binary classification.\n",
    "\n",
    "For Python, we can use `sklearn.datasets.make_classification` to generate a similar dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8825b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (100, 3)\n",
      "Feature matrix X dimensions: (100, 2)\n",
      "Classes: [1 2]\n"
     ]
    }
   ],
   "source": [
    "#| label: data_generation\n",
    "\n",
    "# 2-class normal distribution data\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, \n",
    "                           n_informative=2, n_clusters_per_class=1, \n",
    "                           random_state=509, class_sep=1.5)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(X, columns=['x.1', 'x.2'])\n",
    "data['classes'] = y + 1  # Convert from 0,1 to 1,2 to match R output\n",
    "\n",
    "# Extract features and target\n",
    "X = data[['x.1', 'x.2']].values\n",
    "y = data['classes'].values\n",
    "\n",
    "# Display the data structure\n",
    "print(\"Data dimensions:\", data.shape)\n",
    "print(\"Feature matrix X dimensions:\", X.shape)\n",
    "print(\"Classes:\", np.unique(y))  # we will need to convert them to -1 and +1 later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73cbc0",
   "metadata": {},
   "source": [
    "label:\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45135490",
   "metadata": {},
   "source": [
    "label: visual_inspection\n",
    "# Visual Inspection of the Data\n",
    "\n",
    "We can see that the data is mostly linearly separable, but there are some points that are close to the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958c1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: plot_data\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create scatter plot with different symbols for each class\n",
    "class1_mask = data['classes'] == 1\n",
    "class2_mask = data['classes'] == 2\n",
    "\n",
    "plt.scatter(data.loc[class1_mask, 'x.1'], data.loc[class1_mask, 'x.2'], \n",
    "           marker='_', s=100, c='black', label='Class 1')\n",
    "plt.scatter(data.loc[class2_mask, 'x.1'], data.loc[class2_mask, 'x.2'], \n",
    "           marker='+', s=100, c='black', label='Class 2')\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Two-Class Dataset')\n",
    "plt.legend(title='Classes')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfa541",
   "metadata": {},
   "source": [
    "label: train_pegasos\n",
    "# Training the PEGASOS Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: train_pegasos\n",
    "\n",
    "# Recode target variable: class 2 becomes +1, class 1 becomes -1\n",
    "y = np.where(y == 2, 1, -1)\n",
    "\n",
    "# Train PEGASOS model\n",
    "# Note: lambda = 1/(C*n) where C is the SVM regularization parameter\n",
    "# Add column of ones for intercept\n",
    "X_with_intercept = np.column_stack([np.ones(len(y)), X])\n",
    "model_pegasos = pegasos_linear(y, X_with_intercept, lambda_param=1/(C * len(y)))\n",
    "\n",
    "print(\"PEGASOS model parameters:\")\n",
    "print(f\"Intercept: {model_pegasos[0]}\")\n",
    "print(f\"Coefficients: {model_pegasos[1:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa538f54",
   "metadata": {},
   "source": [
    "label: decision_boundaries\n",
    "# Decision Boundaries Visualization\n",
    "\n",
    "Now we'll use the trained model to visualize the decision boundaries. Additionally, for comparison we will also fit a Logistic Regression model and visualize its decision boundary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: plot_boundaries\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Recreate the plot with both classes\n",
    "class1_mask = data['classes'] == 1\n",
    "class2_mask = data['classes'] == 2\n",
    "\n",
    "plt.scatter(data.loc[class1_mask, 'x.1'], data.loc[class1_mask, 'x.2'], \n",
    "           marker='_', s=100, c='black')\n",
    "plt.scatter(data.loc[class2_mask, 'x.1'], data.loc[class2_mask, 'x.2'], \n",
    "           marker='+', s=100, c='black')\n",
    "\n",
    "# Add PEGASOS decision boundary\n",
    "# Decision boundary equation: θ₀ + θ₁x₁ + θ₂x₂ = 0\n",
    "# Rearranged: x₂ = -(θ₀ + θ₁x₁)/θ₂\n",
    "x_range = np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100)\n",
    "pegasos_boundary = -(model_pegasos[0] + model_pegasos[1] * x_range) / model_pegasos[2]\n",
    "plt.plot(x_range, pegasos_boundary, color='#D55E00', linewidth=2, label='PEGASOS')\n",
    "\n",
    "# Compare to logistic regression\n",
    "# Convert back to original classes for sklearn\n",
    "y_for_sklearn = np.where(y == 1, 2, 1)  # Convert back to 1,2 for compatibility\n",
    "data_for_logreg = pd.DataFrame({'x.1': X[:, 0], 'x.2': X[:, 1], 'classes': y_for_sklearn})\n",
    "model_logreg = LogisticRegression(fit_intercept=True, random_state=2, max_iter=1000)\n",
    "model_logreg.fit(X, y_for_sklearn)\n",
    "\n",
    "# Get logistic regression coefficients\n",
    "logreg_coef = model_logreg.coef_[0]\n",
    "logreg_intercept = model_logreg.intercept_[0]\n",
    "logreg_boundary = -(logreg_intercept + logreg_coef[0] * x_range) / logreg_coef[1]\n",
    "plt.plot(x_range, logreg_boundary, color='#0800ffff', linewidth=2, linestyle='--', label='Logistic')\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Decision Boundaries Comparison')\n",
    "plt.legend(title='Models')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7251c4",
   "metadata": {},
   "source": [
    "label: evaluation\n",
    "\n",
    "# Evaluating the PEGASOS Model\n",
    "\n",
    "We'll compute the accuracy and the confusion matrix. In practice, other metrics should be also considered, e.g. precision, recall, F1-score (threshold dependent); ROC AUC, PR AUC (threshold independent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: evaluate_pegasos\n",
    "\n",
    "# Compute decision values (distances from decision boundary)\n",
    "f_pegasos = X_with_intercept @ model_pegasos  # we already have intercept column\n",
    "\n",
    "# Check classification accuracy\n",
    "# Positive values indicate class +1, negative values indicate class -1\n",
    "predictions = np.sign(f_pegasos)\n",
    "accuracy = np.mean(predictions == y)\n",
    "\n",
    "print(\"PEGASOS Classification Results:\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display confusion matrix (sign of decision values vs true labels)\n",
    "print(\"\\nConfusion Matrix (decision sign vs true labels):\")\n",
    "confusion_values = np.sign(f_pegasos * y)\n",
    "unique_values, counts = np.unique(confusion_values, return_counts=True)\n",
    "confusion_dict = dict(zip(unique_values, counts))\n",
    "print(f\"Correct classifications (value=1): {confusion_dict.get(1, 0)}\")\n",
    "print(f\"Incorrect classifications (value=-1): {confusion_dict.get(-1, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe9368",
   "metadata": {},
   "source": [
    "label: kernellab_or_sklearn\n",
    "# Using `kernlab` (R) or `sklearn.svm.SVC` (Python) for Comparison\n",
    "\n",
    "Accuracy is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: train_kernlab_or_sklearn\n",
    "\n",
    "# Train sklearn SVM with linear kernel (equivalent to kernlab)\n",
    "# Note: we cannot expect a PERFECT match due to different optimization approaches\n",
    "# Convert y back to 0,1 for sklearn\n",
    "y_sklearn = np.where(y == 1, 1, 0)\n",
    "\n",
    "model_sklearn = SVC(kernel='linear', C=C, random_state=2)\n",
    "model_sklearn.fit(X, y_sklearn)\n",
    "\n",
    "# Get decision values from sklearn\n",
    "f_sklearn = model_sklearn.decision_function(X)\n",
    "\n",
    "# Convert back to -1,1 format for comparison\n",
    "y_sklearn_signed = np.where(y_sklearn == 1, 1, -1)\n",
    "\n",
    "print(\"sklearn SVM Classification Results:\")\n",
    "sklearn_predictions = np.sign(f_sklearn)\n",
    "# Handle the case where decision function returns exactly 0\n",
    "sklearn_predictions = np.where(sklearn_predictions == 0, 1, sklearn_predictions)\n",
    "sklearn_correct = np.sum(sklearn_predictions == y)\n",
    "sklearn_accuracy = sklearn_correct / len(y)\n",
    "print(f\"Accuracy: {sklearn_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display confusion matrix for sklearn\n",
    "print(\"\\nsklearn Confusion Matrix:\")\n",
    "sklearn_confusion_values = np.sign(f_sklearn * y)\n",
    "sklearn_unique_values, sklearn_counts = np.unique(sklearn_confusion_values, return_counts=True)\n",
    "sklearn_confusion_dict = dict(zip(sklearn_unique_values, sklearn_counts))\n",
    "print(f\"Correct classifications (value=1): {sklearn_confusion_dict.get(1, 0)}\")\n",
    "print(f\"Incorrect classifications (value=-1): {sklearn_confusion_dict.get(-1, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a9393",
   "metadata": {},
   "source": [
    "label: comparison_coefs\n",
    "## Comparison of Model Coefficients\n",
    "\n",
    "We can see that both the predictions and coefficients are almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3442f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: compare_models\n",
    "\n",
    "# Compare decision values between models\n",
    "decision_diff = np.abs(f_sklearn - f_pegasos)\n",
    "print(\"Decision Values Comparison:\")\n",
    "print(f\"Range of absolute differences: [{decision_diff.min():.6f}, {decision_diff.max():.6f}]\")\n",
    "print(f\"Mean absolute difference: {decision_diff.mean():.6f}\")\n",
    "\n",
    "# Extract and compare model coefficients\n",
    "# For sklearn: coefficients are directly available\n",
    "sklearn_params = np.array([\n",
    "    model_sklearn.intercept_[0],  # intercept\n",
    "    model_sklearn.coef_[0, 0],    # coefficient for x1\n",
    "    model_sklearn.coef_[0, 1]     # coefficient for x2\n",
    "])\n",
    "\n",
    "# Combine parameters for comparison\n",
    "all_params = np.array([\n",
    "    model_pegasos,     # PEGASOS parameters\n",
    "    sklearn_params     # sklearn parameters\n",
    "])\n",
    "\n",
    "print(\"\\nModel Parameters Comparison:\")\n",
    "param_names = ['Intercept', 'Coeff_x1', 'Coeff_x2']\n",
    "print(f\"{'Model':<10} {'Intercept':<12} {'Coeff_x1':<12} {'Coeff_x2':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'PEGASOS':<10} {model_pegasos[0]:<12.6f} {model_pegasos[1]:<12.6f} {model_pegasos[2]:<12.6f}\")\n",
    "print(f\"{'sklearn':<10} {sklearn_params[0]:<12.6f} {sklearn_params[1]:<12.6f} {sklearn_params[2]:<12.6f}\")\n",
    "\n",
    "print(\"\\nParameter differences:\")\n",
    "param_diff = np.abs(all_params[0] - all_params[1])\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"{name}: {param_diff[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081af009",
   "metadata": {},
   "source": [
    "label: emp_risk_comparions\n",
    "## Comparison of empirical risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47344478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: calculate_risk\n",
    "\n",
    "# Define empirical risk function for SVM\n",
    "# Risk = 0.5 * ||w||² + C * Σ max(0, 1 - y_i * f(x_i))\n",
    "def emp_risk(theta):\n",
    "    f = X_with_intercept @ theta\n",
    "    # Hinge loss: max(0, 1 - y_i * f(x_i))\n",
    "    hinge_losses = np.maximum(0, 1 - y * f)\n",
    "    return 0.5 * np.sum(theta[1:3]**2) + C * np.sum(hinge_losses)\n",
    "\n",
    "# Calculate empirical risk for both models\n",
    "risk_pegasos = emp_risk(model_pegasos)\n",
    "risk_sklearn = emp_risk(sklearn_params)\n",
    "\n",
    "print(\"Empirical Risk Comparison:\")\n",
    "print(f\"PEGASOS risk: {risk_pegasos:.4f}\")\n",
    "print(f\"sklearn risk: {risk_sklearn:.4f}\")\n",
    "\n",
    "risk_difference_abs = abs(risk_pegasos - risk_sklearn)\n",
    "print(f\"Risk difference: {risk_difference_abs:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a37c29",
   "metadata": {},
   "source": [
    "label: plotting_everything\n",
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52842280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: plot_margins_prep\n",
    "\n",
    "# Use sklearn parameters for margin visualization\n",
    "params_sklearn = sklearn_params  # sklearn parameters\n",
    "\n",
    "# Calculate margin width\n",
    "# Margin = 1 / ||w|| where w are the feature coefficients (excluding intercept)\n",
    "margin = 1 / np.sqrt(np.sum(params_sklearn[1:3]**2))\n",
    "\n",
    "# Calculate margin boundaries\n",
    "# The margin lines are parallel to the decision boundary\n",
    "m = -params_sklearn[1] / params_sklearn[2]  # Slope of decision boundary\n",
    "\n",
    "# Transform margin width to intercept shift\n",
    "# (margin shift is orthogonal to decision boundary)\n",
    "t_0 = margin / np.cos(np.arctan(m))\n",
    "\n",
    "# Find support vectors on decision boundary\n",
    "# Support vectors have decision values close to ±1\n",
    "sv_tolerance = 0.02  # tolerance for identifying support vectors on boundary\n",
    "sv_indices = model_sklearn.support_\n",
    "f_sklearn_sv = f_sklearn[sv_indices]\n",
    "nv_sv_mask = np.abs(np.abs(f_sklearn_sv) - 1) < sv_tolerance\n",
    "\n",
    "print(\"Support Vector Information:\")\n",
    "print(f\"Total support vectors: {len(sv_indices)}\")\n",
    "print(f\"Support vectors on margin: {np.sum(nv_sv_mask)}\")\n",
    "print(f\"Margin width: {margin:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295d775",
   "metadata": {},
   "source": [
    "label: complete_visualization\n",
    "## Complete visualization\n",
    "\n",
    "- We can see that all the models produce almost identical decision boundary\n",
    "- The margins are plotted for the `kernlab`'s (R) / `sklearn.svm.SVC` (Python) model\n",
    "- We have 12 support vectors, from which 4 lay on the margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05237092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: complete_visualization\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot data points\n",
    "class1_mask = data['classes'] == 1\n",
    "class2_mask = data['classes'] == 2\n",
    "\n",
    "plt.scatter(data.loc[class1_mask, 'x.1'], data.loc[class1_mask, 'x.2'], \n",
    "           marker='_', s=100, c='black')\n",
    "plt.scatter(data.loc[class2_mask, 'x.1'], data.loc[class2_mask, 'x.2'], \n",
    "           marker='+', s=100, c='black')\n",
    "\n",
    "# Define x range for boundary lines\n",
    "x_range = np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100)\n",
    "\n",
    "# PEGASOS decision boundary\n",
    "pegasos_boundary = -(model_pegasos[0] + model_pegasos[1] * x_range) / model_pegasos[2]\n",
    "plt.plot(x_range, pegasos_boundary, color='#d40808ff', linewidth=2, label='PEGASOS')\n",
    "\n",
    "# Logistic regression boundary\n",
    "logreg_boundary = -(logreg_intercept + logreg_coef[0] * x_range) / logreg_coef[1]\n",
    "plt.plot(x_range, logreg_boundary, color='#0800ffff', linewidth=2, label='Logistic')\n",
    "\n",
    "# sklearn decision boundary\n",
    "sklearn_boundary = -(params_sklearn[0] + params_sklearn[1] * x_range) / params_sklearn[2]\n",
    "plt.plot(x_range, sklearn_boundary, color='#D55E00', linewidth=2, label='sklearn SVM')\n",
    "\n",
    "# Add margin boundaries\n",
    "margin_upper = -(params_sklearn[0] + params_sklearn[1] * x_range) / params_sklearn[2] + t_0\n",
    "margin_lower = -(params_sklearn[0] + params_sklearn[1] * x_range) / params_sklearn[2] - t_0\n",
    "plt.plot(x_range, margin_upper, color='#0072B2', linestyle='--', linewidth=1, label='Margin')\n",
    "plt.plot(x_range, margin_lower, color='#0072B2', linestyle='--', linewidth=1)\n",
    "\n",
    "# Highlight support vectors on margin\n",
    "sv_on_margin_indices = sv_indices[nv_sv_mask]\n",
    "if len(sv_on_margin_indices) > 0:\n",
    "    plt.scatter(X[sv_on_margin_indices, 0], X[sv_on_margin_indices, 1], \n",
    "               s=200, facecolors='none', edgecolors='red', linewidth=2, \n",
    "               label='Support Vectors')\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('SVM with Margins and Support Vectors')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
