\begin{algorithm}[H]
  \begin{footnotesize}
  \begin{center}
  \caption{Tree Algorithm for Gradient Boosting.}
    \begin{algorithmic}[1]
      \State \textbf{Input: } All observations $\mathcal{N}$ and risk function $\mathcal{R}$
      \State \textbf{Output: } $\mathcal{N}_l^{j^\ast, s^\ast}$ and $\mathcal{N}_r^{j^\ast, s^\ast}$
      \For{$j = x_1 \dots x_p$}
      \For{every split $s$ on feature $j$}
          %\State For all $i$: $\rmi = -\left[\fp{\Lxyi}{\fxi}\right]_{f=\fmdh}$
          %\State Fit regr. tree to the $\rmi$, giving terminal regions $\Rtm,
          %\ t = 1,\ldots,\Tm$
        %\For{$t = 1 \to \Tm$}
       % $$
        %\hat{\mathbf{c}}^{[m]} = \argmin_{(c_1,\dots,c_{T^{[m]}})}\sum_{i = 1}^n L(\yi, \fmdh(\xi) + \bmm(\xi, c_1,\dots,c_{T^{[m]}})).
        %$$
         \State $\mathcal{N}_l^{j,s} = \{ i \in \mathcal{N}\}_{j^{(i)} \leq s}$
            \State $\mathcal{N}_r^{j,s} = \{i \in \mathcal{N}\}_{j^{(i)} > s}$ 
              
            % objective I for lambda_C and split point t
            \State Find $c$ which minimizes $\mathcal{R}$ for each node
            \State $\mathcal{I}(j, s) = \mathcal{R}(\mathcal{N}_l^{j,s}) + \mathcal{R}(\mathcal{N}_r^{j,s})$
        \EndFor
        % find optimal split point t* for lambda_C
        
       
         % \State $\fmh_t = \argmin_{\fmdh(\xi) + c} \sum \limits_{\xi \in \Rtm} L(\yi, \fmdh(\xi) + c)$
        %\EndFor
        %\State $\bmmh(\xv) = \sum_{t=1}^{T} \ctmh \mathds{1}_{\{x \in R_t\}} $
        %\State Update $\fmh(\xv) = \fmdh(\xv) + \bmmh(\xi, c_1,\dots,c_{T^{[m]}})$
      \EndFor
      \State $(j^\ast, s^\ast) \in \argmin\nolimits_{j, s} \mathcal{I}(j, s)$
    \end{algorithmic}
    \end{center}
    \end{footnotesize}
\end{algorithm}
