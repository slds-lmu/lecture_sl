%Suggested order of slides
% slides-info-entropy
% slides-info-diffent
% slides-info-sourcecoding
% slides-info-kl
% slides-info-cross-entropy-kld
% slides-info-ml
% slides-info-mutual-info

\subsection{Entropy I}
\includepdf[pages=-]{../slides-pdf/slides-info-entropy.pdf}

\subsection{Entropy II}
\includepdf[pages=-]{../slides-pdf/slides-info-entropy2.pdf}

\subsection{Differential Entropy}
\includepdf[pages=-]{../slides-pdf/slides-info-diffent.pdf}

\subsection{Kullback-Leibler Divergence}
\includepdf[pages=-]{../slides-pdf/slides-info-kl.pdf}

\subsection{Cross-Entropy and KL}
\includepdf[pages=-]{../slides-pdf/slides-info-cross-entropy-kld.pdf}

% bis hier fertig dez 23
\subsection{Information Theory for Machine Learning}
\includepdf[pages=-]{../slides-pdf/slides-info-ml.pdf}

\subsection{Joint Entropy and Mutual Information I}
\includepdf[pages=-]{../slides-pdf/slides-info-mutual-info.pdf}

\subsection{Joint Entropy and Mutual Information II}
\includepdf[pages=-]{../slides-pdf/slides-info-mutual-info2.pdf}

\subsection{Entropy and Optimal Code Length}
\includepdf[pages=-]{../slides-pdf/slides-info-sourcecoding.pdf}

\subsection{Entropy and Optimal Code Length II}
\includepdf[pages=-]{../slides-pdf/slides-info-sourcecoding2.pdf}

\subsection{Mutual Information under Reparametrization (Deep-Dive)}
\includepdf[pages=-]{../slides-pdf/slides-info-mi-deepdive.pdf}



