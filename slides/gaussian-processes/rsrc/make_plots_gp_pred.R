
library(knitr)
library(mlr)
library(mlrMBO)
library(ggplot2)
library(gridExtra)
library(reshape2)
library(kernlab)
library(mvtnorm)
library(gptk)
library(smoof)
library(viridis)


x1 <- - 0.5
x2 <- 0.5
f.x1 <- 1

k <- exp(-0.5 * (x2 - x1)^2)

K <- matrix(c(1, k, k, 1), nrow = 2)

data.grid <- expand.grid(X1 = seq(-4, 4, length.out = 200),
                         X2 = seq(-4, 4, length.out = 200))
data.grid <- cbind(data.grid,
                   prob = mvtnorm::dmvnorm(data.grid, mean = c(0, 0), sigma = K))

x <- seq(-4, 4, by = 0.01)
y <- dnorm(x = x, mean = 0, sd = 1)
p1 <- ggplot(data = data.frame(x = x, y = y)) +
  geom_line(aes(x = x, y = y), lty = 2) +
  theme_bw() +
  coord_fixed(xlim = c(-4, 4), ylim = c(0, 1), ratio = 8) +
  ggtitle("Marginal distribution of f(x*)") +
  xlab("f(x*)") +
  ylab("density")

p4 <- p1 +
  ggtitle("Marginal distribution of f(x)") +
  xlab("f(x)")

p2 <- ggplot(data.grid, aes(x = X1, y = X2, z = prob, fill = prob)) +
  geom_raster(aes(fill = prob)) +
  geom_contour(colour = "white") +
  coord_fixed(xlim = c(-4, 4), ylim = c(-4, 4), ratio = 1) +
  theme_bw() +
  theme(legend.position = "none") +
  ggtitle("Bivariate Normal Density") +
  xlab("f(x)") +
  ylab("f(x*)") +
  scale_fill_viridis(end = 0.9)

p3 <- ggplot() +
  geom_line(data = data.frame(x = x, y = rep(0, length(x))),
            aes(x = x, y = y),
            lty = 2) +
  coord_fixed(xlim = c(-2, 2), ylim = c(-4, 4), ratio = 1 / 2) +
  ggtitle("Posterior process") +
  theme_bw() +
  ylab("f(x)")

p <- grid.arrange(p1, p2, p3, p4, ncol = 2)
ggsave(filename = "../figure/gp_pred/1.pdf", plot = p, width = 7, height = 5)
###########################################################

p3 <- p3 +
  annotate(x = x1, y = f.x1, colour = "red", size = 2, geom = "point") +
  annotate(x = - 0.5, y = 1.6,
           label = "training point",
           colour = "red",
           geom = "text")
p <- grid.arrange(p1, p2, p3, p4, ncol = 2)
ggsave(filename = "../figure/gp_pred/2.pdf", plot = p, width = 7, height = 5)

############################################################
p4 <- p4 +
  geom_vline(xintercept = f.x1, colour = "red") +
  annotate(x = f.x1 - 1, y = 0.5,
           label = "observed \n value", colour = "red", geom = "text")

p2 <- p2 + geom_vline(xintercept = f.x1, colour = "red")

p <- grid.arrange(p1, p2, p3, p4, ncol = 2)
ggsave(filename = "../figure/gp_pred/3.pdf", plot = p, width = 7, height = 5)
###########################################################

m.cond <- K[1, 2] / K[1, 1] * 1
s.cond <- K[2, 2] - K[1, 2]^2 / K[1, 1]

y.post <- dnorm(x = x, mean = m.cond, sd = s.cond)
p1 <- p1 +
  geom_line(data = data.frame(x = x, y = y.post), aes(x = x, y = y, colour = y)) +
  theme(legend.position = "none") +
  scale_color_viridis(end = 0.9)

p <- grid.arrange(p1, p2, p3, p4, ncol = 2)
ggsave(filename = "../figure/gp_pred/4.pdf", plot = p, width = 7, height = 5)

#########################################################

p1 <- p1 +
  geom_vline(xintercept = m.cond, colour = "orange")

p3 <- p3 +
  annotate(x = 0.5, y = m.cond, colour = "orange", size = 2, geom  ="point") +
  annotate(x = 0.5, y = m.cond + 0.6,
           label = "prediction", colour = "orange", geom = "text")

p <- grid.arrange(p1, p2, p3, p4, ncol = 2)
ggsave(filename = "../figure/gp_pred/5.pdf", plot = p, width = 7, height = 5)

#########################################################

d.process <- data.frame(x = seq(-2, 2, by = 0.01))
d.process$k <- sapply(d.process, function(x) exp(-0.5 * (x - x1)^2))
d.process$m.post <- d.process$k * 1
d.process$k.post <- 1 - d.process$k^2

p3 <- p3 +
  geom_line(data = d.process, aes(x = x, y = m.post)) +
  geom_line(data = d.process, aes(x = x, y = m.post + 2 * k.post), color = "grey") +
  geom_line(data = d.process, aes(x = x, y = m.post - 2 * k.post), color = "grey") +
  geom_ribbon(data = d.process,
              aes(x = x, ymax = m.post + 2 * k.post, ymin = m.post - 2 * k.post),
              fill = "grey", alpha = .5)

p <- grid.arrange(p1, p2, p3, p4, ncol = 2)
ggsave(filename = "../figure/gp_pred/6.pdf", plot = p, width = 7, height = 5)
##########################################################

set.seed(124415)
x <- seq(-5, 5, by = 0.01)
y <- cos(x)
df <- data.frame(x = x, y = y)
train <- sample(1:length(x), 5)
istrain <- 1:length(x) %in% train

configureMlr(show.info = FALSE, show.learner.output = FALSE)
tsk <- makeRegrTask(id = "GP as interpolator", data = df, target = "y")
lrn <- makeLearner("regr.km", predict.type = "se", par.vals = list(nugget.estim = FALSE))
mod <- train(lrn, tsk, subset = train)
pred <- predict(mod, tsk)
pred <- cbind(pred$data, x = df$x, type = istrain)

p <- ggplot() + geom_point(data = pred[train, ], aes(x = x, y = truth), size = 1, colour = "red")
p <- p + geom_line(data = pred, aes(x = x, y = response))
p <- p + geom_ribbon(data = pred, aes(x = x, ymin = response - 2 * se, ymax = response + 2 * se), fill = "grey70", alpha = 0.3)
p <- p + theme_bw() + ylab(expression(hat(f)(x))) +
  labs(caption = "After observing the training points (red), the posterior process (black) interpolates the training points.\n (k(x,x') is MatÃ¨rn with nu = 2.5, the default for DiceKriging::km)")
ggsave(filename = "../figure/gp_pred/gp_interpolator.pdf", plot = p, width = 6, height = 3)

#########################################################

configureMlr(show.info = FALSE, show.learner.output = FALSE)

set.seed(1234)
obj.fun <- makeHimmelblauFunction()
des <- generateDesign(n = 10, par.set = getParamSet(obj.fun), )
des$y <- apply(des, 1, obj.fun)
surr.km <- makeLearner("regr.km", predict.type = "se", covtype = "gauss")

control <- makeMBOControl()
control <- setMBOControlTermination(control, iters = 5)
control <- setMBOControlInfill(control, crit = makeMBOInfillCritEI())

run <- mbo(obj.fun, design = des, learner = surr.km, control = control, show.info = TRUE)

points <- data.frame(run$opt.path)

x <- seq(-4.5, 4.5, length.out = 200)
z <- expand.grid(x1 = x, x2 = x)
pred <- predict(run$models[[1]], newdata = z)
z$se <- pred$data$se
z$pred <- pred$data$response


p1 <- ggplot() +
  ylim(c(-4.5, 4.5)) +
  xlim(c(-4.5, 4.5)) +
  geom_raster(data = z, aes(x = x1, y = x2, fill = pred), alpha = 0.8) +
  geom_point(data = points, aes(x = x1, y = x2), size = 3, color = "orange") +
  scale_fill_gradient(low = "black", high = "white", name = "post. mean") +
  xlab(expression(x[1])) +
  ylab(expression(x[2])) +
  theme(legend.text = element_text(size = 12))

p2 <- ggplot() +
  ylim(c(-4.5, 4.5)) +
  xlim(c(-4.5, 4.5)) +
  geom_raster(data = z, aes(x = x1, y = x2, fill = se), alpha = 0.8) +
  geom_point(data = points, aes(x = x1, y = x2), size = 3, color = "orange") +
  labs(fill = "post. variance") +
  xlab(expression(x[1])) +
  ylab(expression(x[2])) +
  theme(legend.text = element_text(size = 12))

ggsave(filename = "../figure/gp_pred/post_mean.pdf",
       plot = p1, width = 5.5, height = 4)
ggsave(filename = "../figure/gp_pred/post_variance.pdf",
       plot = p2, width = 5.5, height = 4)
########################################################

set.seed(124415)
n <- 6
x.obs <- runif(n, -2, 2)
y.obs <- x.obs^2 + rnorm(n)
df <- data.frame(x = x.obs, y = y.obs)

preddf <- data.frame(x = seq(-2, 2, by = 0.01))

configureMlr(show.info = FALSE, show.learner.output = FALSE)
tsk <- makeRegrTask(id = "GP as interpolator", data = df, target = "y")
lrn <- makeLearner("regr.km", predict.type = "se", par.vals = list(nugget.estim = TRUE, covtype = "gauss"))
mod <- train(lrn, tsk)
pred <- cbind(preddf, predict(mod, newdata = preddf)$data)

p <- ggplot() +
  geom_point(data = df, aes(x = x, y = y), size = 1, colour = "red") +
  geom_line(data = pred, aes(x = x, y = response)) +
  geom_ribbon(data = pred,
              aes(x = x, ymin = response - 2 * se, ymax = response + 2 * se),
              fill = "grey70", alpha = 0.3) +
  theme_bw() +
  ylab(expression(hat(f)(x))) +
  labs(caption = "After observing the training points (red), we have a nugget-band around the oberved points. \n (k(x,x') is the squared exponential)")

ggsave(filename = "../figure/gp_pred/gp_regression.pdf",
       plot = p, width = 6, height = 3)








