%Blank Lecture
%This file is a child of preamble.Rnw in the style folder
%if you want to add stuff to the preamble go there to make
%your changes available to all childs

<<setup-child, include = FALSE>>=
library(knitr)
library(mlr)
library(mlbench)
library(ggplot2)
library(BBmisc)
library(reshape)
set_parent("../style/preamble.Rnw")
@



\lecturechapter{\Sexpr{lecture_nr}}{Regularization in the Linear Model}
\lecture{Fortgeschrittene Computerintensive Methoden}


\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}



\section{Optimization Perspective}

\begin{vbframe}{Ridge: Equivalent Formulations} 


\textbf{Claim:} The following formulations are equivalent: 

\vspace*{-0.5cm}

\begin{eqnarray}
  \min_{\thetab} && g_\lambda(\bm{\theta}) := \|\bm{y} - \bm{X}\bm{\theta}\|^2 + \lambda \|\thetab\|^2 
\label{eq:form1}
\end{eqnarray}

\begin{align}
\begin{split}
\min_{\bm{\theta}} & \quad \|\bm{y} - \bm{X}\bm{\theta}\|^2 \\
\text{s.t.} & \quad \|\bm{\theta}\|_2^2 - t \le 0
\end{split} 
\label{eq:form2}
\end{align}

\textbf{Sketch of Proof}: Let us consider  \eqref{eq:form1} first. Let $\thetah_{Ridge}$ be the minimum of $g_\lambda(\bm{\theta})$. Necessarily, the gradient of $g_\lambda$ at $\thetah_{Ridge}$ is $0$:

$$
  \nabla g_\lambda(\thetah_{Ridge}) = - 2 \bm{X}^T \bm{y} + 2  \bm{X}^T\bm{X} \thetah_{Ridge}+ 2 \lambda \thetah_{Ridge} = 0
$$

\vspace{0.2cm} 

We show that we can find a value $t$ such that $\thetah_{Ridge}$ is also the optimal solution to problem \eqref{eq:form2}.

\framebreak 

We calculate the Lagrangian of \eqref{eq:form2}:

\vspace*{-0.5cm}
\begin{eqnarray*}
  L(\bm{\theta}, \alpha) &=& \|\bm{y} - \bm{X}\bm{\theta}\|^2 + \alpha (\|\bm{\theta}\|^2_2 - t). 
\end{eqnarray*}

The first KKT condition says: 

$$
\nabla_\theta L(\bm{\theta}, \alpha)= 
  - 2 \bm{X}^T \bm{y} + 2  \bm{X}^T\bm{X} \thetab + 2 \lambda \thetab = 0
$$

Since $\nabla g_\lambda(\thetah_{Ridge}) = 0$, this is satisfied if we set $\bm{\theta} = \thetah_{Ridge}$ and $\alpha = \lambda$. 

\vspace*{0.2cm}  

The KKT conditions also require that complementarity is fulfilled: 
$$
\alpha(\|\bm{\theta}\|^2_2 - t) = 0. 
$$

This is satisfied if we set $t = \|\thetah_{Ridge}\|^2$. 

\vspace*{0.2cm} 

The converse is also true: The optimal solution to problem \eqref{eq:form2} is also a solution to problem \eqref{eq:form1} if we set $\lambda = \alpha$.


\end{vbframe}



\section{An Optimization Perspective on Regularization}





\endlecture
